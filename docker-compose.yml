# docker-compose.yml

services:
  postgres:
    image: postgres:12.6
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: airflow
    ports:
      - "127.0.0.1:5432:5432" # Local access only
    networks:
      - ndsnet
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  webserver:
    image: astro-runtime:latest
    container_name: airflow-webserver
    restart: always
    ports:
      - "8080:8080"
    networks:
      - ndsnet
    environment:
      AIRFLOW_CONN_STOCK_POSTGRES: "postgresql://postgres:postgres@postgres:5432/airflow"

  scheduler:
    image: astro-runtime:latest
    container_name: airflow-scheduler
    restart: always
    command: ["airflow", "scheduler"]
    networks:
      - ndsnet
    environment:
      AIRFLOW_CONN_STOCK_POSTGRES: "postgresql://postgres:postgres@postgres:5432/airflow"

  triggerer:
    image: astro-runtime:latest
    container_name: airflow-triggerer
    restart: always
    command: ["airflow", "triggerer"]
    networks:
      - ndsnet
    environment:
      AIRFLOW_CONN_STOCK_POSTGRES: "postgresql://postgres:postgres@postgres:5432/airflow"

  minio:
    image: minio/minio:RELEASE.2024-06-13T22-53-53Z
    container_name: minio
    hostname: minio
    restart: always
    volumes:
      - ./include/data/minio:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ndsnet

  spark-master:
    image: airflow/spark-master
    build: ./spark/master
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - ndsnet

  spark-worker:
    image: airflow/spark-worker
    build: ./spark/worker
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - ndsnet

  metabase:
    image: metabase/metabase:v0.52.8.4
    container_name: metabase
    restart: always
    ports:
      - "3000:3000"
    volumes:
      - ./include/data/metabase:/metabase-data
    networks:
      - ndsnet

  docker-proxy:
    image: alpine/socat
    container_name: docker-proxy
    command: "TCP4-LISTEN:2375,fork,reuseaddr UNIX-CONNECT:/var/run/docker.sock"
    ports:
      - "2376:2375"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - ndsnet

  sqlite-debug:
    image: nouchka/sqlite3:latest
    container_name: sqlite-debug
    restart: unless-stopped
    volumes:
      - ./include/data/sqlite:/data
    working_dir: /data
    stdin_open: true
    tty: true
    networks:
      - ndsnet
    command: ["sh", "-c", "while true; do echo 'SQLite debug container is running...'; sleep 5; done"]

networks:
  ndsnet:
    driver: bridge